Document = Dict[str, Any]
DocInput = Union[str, Document]
class SearchIndex:
def __init__(
        self,
        documents: Iterable[DocInput],
        *,
        title_field: str = "title",
        text_field: str = "text",
        id_field: str = "id",
        functions: Optional[Dict[str, Callable]] = None,
    ) -> None:
        if not isinstance(title_field, str) or not title_field:
            raise ValueError("title_field must be a non-empty string")
        if not isinstance(text_field, str) or not text_field:
            raise ValueError("text_field must be a non-empty string")
        if not isinstance(id_field, str) or not id_field:
            raise ValueError("id_field must be a non-empty string")

        self._title_field = title_field
        self._text_field = text_field
        self._id_field = id_field

        self._docs: List[Document] = []
        for i, d in enumerate(documents):
            if isinstance(d, str):
                self._docs.append({self._id_field: f"doc_{i}", self._text_field: d})
            elif isinstance(d, dict):
                if self._text_field not in d or not isinstance(d[self._text_field], str):
                    raise ValueError(f"Document #{i} missing text field '{self._text_field}'")

                if self._id_field not in d:
                    d = {**d, self._id_field: f"doc_{i}"}
                self._docs.append(d)
            else:
                raise TypeError("Each document must be a str or dict")

        # Inject function library (optionally partial)
        self._fn: Dict[str, Callable] = functions or {}
        self._index: Optional[Dict[str, List[Tuple[Any, int]]]] = None
        self._ready: bool = False
@property
    def doc_count(self) -> int:
        return len(self._docs)

    @property
    def index_built(self) -> bool:
        return self._ready

    @property
    def index_size(self) -> int:
        return 0 if self._index is None else len(self._index)
def __repr__(self) -> str:
        return (
            f"SearchIndex(doc_count={self.doc_count}, "
            f"index_built={self.index_built}, index_size={self.index_size})"
        )

    def __str__(self) -> str:
        status = "ready" if self._ready else "not built"
        return f"<SearchIndex: {self.doc_count} docs, index {status}>"

    # -------------------------
    # Core instance methods (3-5)
    # -------------------------

    def build_index(self) -> bool:
        """
        Build an inverted index over the current documents.

        Uses:
            - clean_text (optional) to normalize doc text
            - build_inverted_index (required)

        Returns
        -------
        bool
            True when the index was built successfully.
        cleaner = self._fn.get("clean_text")
        builder = self._fn.get("build_inverted_index")
        if builder is None:
            raise RuntimeError("build_inverted_index function is required")

        # Prepare corpus: (doc_id, text)
        corpus: List[Tuple[Any, str]] = []
        for d in self._docs:
            text = d[self._text_field]
            text = cleaner(text) if callable(cleaner) else text
            corpus.append((d[self._id_field], text))

        self._index = builder(corpus)  # expected: {term: [(doc_id, freq), ...], ...}
        self._ready = True
        return True

    def search(
        self,
        query: str,
        *,
        method: str = "rank",  # "rank" | "boolean" | "semantic"
        sort: Optional[str] = None,
        order: Optional[str] = None,
        page: int = 1,
        page_size: int = 10,
        snippet_chars: int = 160,
        min_score: Optional[float] = None,
    ) -> Dict[str, Any]:

        if not isinstance(query, str) or not query.strip():
            raise ValueError("query must be a non-empty string")
        if not self._ready:
            raise RuntimeError("index not built; call build_index() first")

        # --- Normalization / formatting ---
        normalizer = self._fn.get("normalize_query")
        formatter = self._fn.get("format_query")
        q_norm = normalizer(query) if callable(normalizer) else query.strip()
        q_formatted = formatter(q_norm) if callable(formatter) else q_norm

        # --- Candidate retrieval & scoring ---
        results: List[Tuple[Any, float]] = []
        if method == "boolean":
            boolean = self._fn.get("boolean_retrieval")
            if boolean is None:
                raise RuntimeError("boolean_retrieval function is not available")
            results = [(doc_id, 1.0) for doc_id in boolean(q_formatted, self._index)]
        elif method == "semantic":
            sem = self._fn.get("semantic_search")
            if sem is None:
                raise RuntimeError("semantic_search function is not available")
            results = sem(q_formatted, self._docs, text_field=self._text_field)
            # expected list of (doc_id, score)
        else:  # "rank" default
            ranker = self._fn.get("rank_documents")
            if ranker is None:
                raise RuntimeError("rank_documents function is required for 'rank' method")
            results = ranker(q_formatted, self._index, self._docs, text_field=self._text_field)

        # Optional score filter
        if min_score is not None:
            results = [(i, s) for (i, s) in results if s is None or s >= min_score]

        # Materialize result rows (attach text, title, etc.)
        doc_by_id = {d[self._id_field]: d for d in self._docs}
        rows: List[Dict[str, Any]] = []
        for doc_id, score in results:
            d = doc_by_id.get(doc_id)
            if not d:
                continue
            text: str = d.get(self._text_field, "")
            title: str = d.get(self._title_field) or str(doc_id)

            # Highlights, snippets, term freq
            highlighter = self._fn.get("highlight_query_terms")
            trunc = self._fn.get("truncate_snippet")
            ctf = self._fn.get("count_term_frequency")

            highlights = highlighter(text, q_formatted) if callable(highlighter) else []
            snippet = trunc(text, q_formatted, max_chars=snippet_chars) if callable(trunc) else text[:snippet_chars]
            term_freq = ctf(text, q_formatted) if callable(ctf) else {}

            rows.append({
                "id": doc_id,
                "title": title,
                "score": score,
                "snippet": snippet,
                "highlights": highlights,
                "term_freq": term_freq,
                "meta": {k: v for k, v in d.items() if k not in (self._id_field, self._text_field)},
            })

        # --- Filter/sort/paginate ---
        fsp = self._fn.get("filter_sort_paginate_results")
        if fsp is None:
            # Minimal fallback if not provided
            rows_sorted = sorted(rows, key=lambda r: (r["score"] is None, -(r["score"] or 0.0)))
            total = len(rows_sorted)
            start = max(0, (page - 1) * page_size)
            end = start + page_size
            items = rows_sorted[start:end]
            payload = {"total": total, "page": page, "page_size": page_size, "items": items}
        else:
            payload = fsp(
                rows,
                sort=sort or ("score" if method != "boolean" else None),
                order=order or "desc",
                page=page,
                page_size=page_size,
            )

        # Optional: final information validation
        validator = self._fn.get("validate_information")
        if callable(validator):
            payload = validator(payload)  # pass-through or cleanup as your project defines

        return payload

    def boolean_search(self, query: str, **kwargs) -> Dict[str, Any]:
        
        return self.search(query, method="boolean", **kwargs)

    def semantic_search(self, query: str, **kwargs) -> Dict[str, Any]:
        return self.search(query, method="semantic", **kwargs)
